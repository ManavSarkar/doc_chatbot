{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Set logging level to INFO\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting the application\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting the application\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a language model, I don't have emotions or feelings like humans do, but I'm functioning properly and ready to help you with any questions or tasks you may have! It's great to chat with you. How can I assist you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 16, 'total_tokens': 69, 'completion_time': 0.044166667, 'prompt_time': 0.002345226, 'queue_time': 0.019151174, 'total_time': 0.046511893}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-09d49eb3-9a19-4d08-b12f-0c791324a1ec-0', usage_metadata={'input_tokens': 16, 'output_tokens': 53, 'total_tokens': 69})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"MISTRALAI_API_KEY\"):\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "model.invoke(\"Hello, how are you!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, DirectoryLoader\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    return PyMuPDFLoader(file_path).load()\n",
    "\n",
    "documents = load_pdf(\"input/gen_ai_langchain_2024.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 361 and Number of Chunks: 1014\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    \n",
    "    # Split the documents into chunks\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "chunks = split_documents(documents)\n",
    "\n",
    "# add unique ids to each chunk combining source, page and start_index\n",
    "for chunk in chunks:\n",
    "    source = chunk.metadata.get(\"source\")\n",
    "    page = chunk.metadata.get(\"page\")\n",
    "    start_index = chunk.metadata.get(\"start_index\")\n",
    "    chunk.metadata[\"id\"] = f\"{source}_{page}_{start_index}\"\n",
    "print(f\"Number of Documents: {len(documents)} and Number of Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'input/gen_ai_langchain_2024.pdf', 'file_path': 'input/gen_ai_langchain_2024.pdf', 'page': 38, 'total_pages': 361, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign 18.0 (Windows)', 'producer': 'Adobe PDF Library 17.0', 'creationDate': \"D:20231215102723+05'30'\", 'modDate': \"D:20231215103312+05'30'\", 'trapped': '', 'start_index': 706, 'id': 'input/gen_ai_langchain_2024.pdf_38_706'}, page_content='skipping tokens. This is a risky strategy because – depending on the threshold of the confidence \\nof the oracle’s responses – the quality could deteriorate.\\nThere’s also a multi-modal version of GPT-4 that incorporates a separate vision encoder, trained \\non joined image and text data, giving the model the capability to read web pages and transcribe \\nwhat’s in images and video.\\nAs can be seen in Figure 1.5, there are quite a few models besides OpenAI’s, some of which are \\nsuitable as a substitute for the OpenAI closed-source models, which we will have a look at.\\nOther LLMs\\nOther notable foundational GPT models besides OpenAI’s include Google DeepMind’s PaLM \\n2, the model behind Google’s chatbot Bard. Although GPT-4 leads most benchmarks in perfor-')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def get_embedding_function():\n",
    "    return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# test the embedding function\n",
    "embedding_function = get_embedding_function()\n",
    "len(embedding_function.embed_query(chunks[100].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:chromadb.api.segment:Collection langchain is not created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing items: 1014\n",
      "No new chunks to add\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "CHROMA_PATH = \"chroma_db\"\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        embedding_function=get_embedding_function(),\n",
    "    )\n",
    "\n",
    "    # add or update the chunks in the chroma db\n",
    "    existing_items = db.get()\n",
    "    if existing_items is None:\n",
    "        existing_items = {\"id\": []}\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "\n",
    "    print(f\"Number of existing items: {len(existing_ids)}\")\n",
    "\n",
    "    new_chunks = [chunk for chunk in chunks if chunk.metadata[\"id\"] not in existing_ids]\n",
    "    new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "    if not new_chunks:\n",
    "        print(\"No new chunks to add\")\n",
    "        return\n",
    "    db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "    db.persist()\n",
    "    \n",
    "import time\n",
    "try:\n",
    "    add_to_chroma(chunks)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based on only on the following context:\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "Answer the question based on the context above: \n",
    "```\n",
    "{question}\n",
    "```\n",
    "\n",
    "If the question is out of context, please answer with \"I don't know\".\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "def query_rag(query_text: str, model):\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        embedding_function=get_embedding_function(),\n",
    "    )\n",
    "    \n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "    \n",
    "    context_text = \"\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate(\n",
    "        [(\"system\", \"You are a helpful AI bot.\"),\n",
    "        (\"human\", PROMPT_TEMPLATE),]\n",
    "    )\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    \n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    sources = [doc.metadata.get(\"id\") for doc, _score in results]\n",
    "    \n",
    "    return response, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:chromadb.api.segment:Collection langchain is not created.\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(AIMessage(content='According to the context, a Transformer is a Deep Learning (DL) architecture that was first introduced in 2017 by researchers at Google and the University of Toronto. It is an encoder-decoder structure that uses self-attention and feed-forward neural networks to capture long-range dependencies in a sentence.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 850, 'total_tokens': 910, 'completion_time': 0.05, 'prompt_time': 0.106209612, 'queue_time': 0.019885206000000002, 'total_time': 0.156209612}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-cbbe125e-fc0a-4d67-b37b-d76c30a0f8ff-0', usage_metadata={'input_tokens': 850, 'output_tokens': 60, 'total_tokens': 910}),\n",
       " ['input/gen_ai_langchain_2024.pdf_42_1500',\n",
       "  'input/gen_ai_langchain_2024.pdf_43_0',\n",
       "  'input/gen_ai_langchain_2024.pdf_43_738',\n",
       "  'input/gen_ai_langchain_2024.pdf_347_0',\n",
       "  'input/gen_ai_langchain_2024.pdf_35_797'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query the model with a question\n",
    "query_rag(\"What is Transformer\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
